{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "ID                                                                              \n",
       "1   0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "2   0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "4   0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5   0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "7   0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
       "\n",
       "     black  lstat  medv  \n",
       "ID                       \n",
       "1   396.90   4.98  24.0  \n",
       "2   396.90   9.14  21.6  \n",
       "4   394.63   2.94  33.4  \n",
       "5   396.90   5.33  36.2  \n",
       "7   395.60  12.43  22.9  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "#import training dataset\n",
    "train_df = pd.read_csv('/home/johan/Desktop/boston-housing/train.csv', index_col='ID')\n",
    "\n",
    "#see the columns in our data\n",
    "#train_df.info()\n",
    "# take a look at the head of the dataset\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (333, 13)\n",
      "y shape: (333,)\n",
      "X_train shape: (233, 13)\n",
      "y_train shape: (233,)\n",
      "X_test shape: (100, 13)\n",
      "y_test shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "#create our X and y\n",
    "#Drop specified labels from rows or columns.\n",
    "#Remove rows or columns by specifying label names and corresponding axis, or by specifying directly index \n",
    "#or column names. When using a multi-index, labels on different levels can be removed by specifying the level.\n",
    "X = train_df.drop('medv', axis=1)\n",
    "y = train_df['medv']\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.7268827869293253\n",
      "Test score: 0.725468795925456\n",
      "RMSE: 4.587100299689435\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lr_model.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lr_model.score(X_test, y_test)))\n",
    "\n",
    "y_pred = lr_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = math.sqrt(mse)\n",
    "\n",
    "print('RMSE: {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must be the same size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-874f7a9f9aa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'black'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow_py3/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3432\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3433\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3434\u001b[0;31m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[1;32m   3435\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3436\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow_py3/lib/python3.5/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m                     warnings.warn(msg % (label_namer, func.__name__),\n\u001b[1;32m   1897\u001b[0m                                   RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0mpre_doc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpre_doc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tensorflow_py3/lib/python3.5/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[1;32m   3962\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3963\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3964\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x and y must be the same size\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3966\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must be the same size"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f08c092ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test,y_pred, color='blue', linewidth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9475767600691033\n",
      "Test score: 0.4676268497187529\n"
     ]
    }
   ],
   "source": [
    "steps = [('scalar', StandardScaler()),('poly', PolynomialFeatures(degree=2)),('model', LinearRegression())]\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X_train, y_train)\n",
    "print('Training score: {}'.format(pipeline.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(pipeline.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if an input sample is two dimensional and of the form [a, b], the degree-2 polynomial features are [1, a, b, a^2, ab, b^2].\n",
    "\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "    z = (x - u) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: [[0 1]\n",
      " [2 3]\n",
      " [4 5]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(6).reshape(3, 2)\n",
    "print ('X:',X)\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolynomialFeatures: (233, 105)\n",
      "-------------------\n",
      "Training Score: 0.9181086448043112\n",
      "Test Score: 0.8287450913722809\n"
     ]
    }
   ],
   "source": [
    "#PolynomialFeatures\n",
    "#Generate polynomial and interaction features.\n",
    "\n",
    "#StandardScaler(), Standardize features by removing the mean and scaling to unit variance\n",
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X_train)\n",
    "print('PolynomialFeatures:',poly.fit_transform(X_train).shape)\n",
    "print('-------------------')\n",
    "\n",
    "steps = [('scalar', StandardScaler()),('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=10, fit_intercept=True))]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train) \n",
    "print('Training Score: {}'.format(ridge_pipe.score(X_train, y_train)))\n",
    "print('Test Score: {}'.format(ridge_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.8483818643379695\n",
      "Test score: 0.8307977758339726\n"
     ]
    }
   ],
   "source": [
    "steps = [('scalar', StandardScaler()),('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.3, fit_intercept=True))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "lasso_pipe.fit(X_train, y_train)\n",
    "\n",
    "print('Training score: {}'.format(lasso_pipe.score(X_train, y_train)))\n",
    "print('Test score: {}'.format(lasso_pipe.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l1+l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://medium.com/coinmonks/regularization-of-linear-models-with-sklearn-f88633a93a2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
